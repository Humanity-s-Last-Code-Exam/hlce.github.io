<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>Humanity's Last Code Exam</title>

    <!-- ======== Fonts & Icons ======== -->
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@100;400&display=swap" rel="stylesheet" />
    <link rel="icon" href="figs/edited_1747725897.png" />

    <!-- ======== Libraries ======== -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/PapaParse/5.3.0/papaparse.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/echarts@5.3.3/dist/echarts.min.js"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0/dist/css/bootstrap.min.css" />
    <link href="https://cdn.jsdelivr.net/npm/prismjs@v1.x/themes/prism.css" rel="stylesheet" />
    <script src="https://cdn.jsdelivr.net/npm/prismjs@v1.x/components/prism-core.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@v1.x/plugins/autoloader/prism-autoloader.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs-bibtex@2.1.0/prism-bibtex.min.js"></script>

    <!-- ======== Styles ======== -->
    <style>
      body {
        font-family: "JetBrains Mono", monospace;
        background-color: #ffffff;
        color: #000000;
      }
      #content {
        width: 50%;
      }
      th,
      td {
        text-align: left;
      }
      th {
        background-color: #f2f2f2;
        cursor: pointer;
        user-select: none;
        font-weight: 800;
        font-size: 1.1em;
      }
      tbody tr {
        transition: background-color 0.2s ease;
      }
      tbody tr:hover {
        background-color: #e9f6ff;
      }
      #notes {
        font-size: 1.1em;
      }
      #notes h3 {
        margin-top: 2em;
        margin-bottom: 1em;
        font-size: 2em;
        text-align: center;
      }
      #notes li {
        font-size: 1.2em;
        font-weight: 300;
        margin: 1em;
      }
      .form-select {
        font-size: 1em;
      }
      @media screen and (max-width: 1400px) {
        body {
          font-size: 1.6vw;
        }
        #content {
          width: 100%;
        }
        h1 {
          font-size: 2em;
        }
        h2 {
          font-size: 1.6em;
        }
        h3 {
          font-size: 1.2em;
        }
        table {
          font-size: small;
        }
      }

        /* ---------- Author & Affiliation ---------- */
        .paper-meta {
          font-size: 1.05rem;       /* é»˜è®¤å­—å·ï¼ˆâ‰ˆ17 pxï¼‰ */
          line-height: 1.4;
        }

        .author-line span,
        .affil-line span {
          white-space: nowrap;      /* é¿å…åå­—/å•ä½è¢«æ‹†è¡Œ */
        }

        .author-line sup,
        .affil-line sup {
          font-size: 0.65em;        /* ä¸Šæ ‡ç•¥å° */
          vertical-align: super;
        }

        .author-line { font-weight: 600; }   /* å§“åç¨åŠ ç²— */
        .affil-line { font-weight: 400; }

        @media (min-width: 1400px) {          /* è¶…å®½å±ç•¥æ”¾å¤§ */
          .paper-meta { font-size: 1.15rem; }
        }

        @media (max-width: 768px) {           /* ç§»åŠ¨ç«¯è‡ªé€‚åº”ç¼©æ”¾ */
          .paper-meta { font-size: 3.5vw; }
          .author-line,
          .affil-line { line-height: 1.3; }
        }
    </style>
  </head>

  <body>
    <div id="content" class="container-fluid d-flex flex-column align-items-center gap-3 py-5 mt-3">
      <h1 class="d-flex align-items-center gap-2 flex-wrap justify-content-center">
        <img src="figs/edited_1747725897.png" alt="HLCE Logo" style="height:40px;" />
        <span>HLCE: Humanity's Last Code Exam</span>
      </h1>

      <h3 class="fw-light text-nowrap">
        <small id="warning">Can Advanced LLMs Conquer Human's Hardest Code Competition?<br /></small>
      </h3>

      <div class="paper-meta text-center my-3">
        <!-- ä½œè€…è¡Œ -->
        <div class="author-line">
          <span>Xiangyang Li<sup>*</sup></span>,
          <span>Xiaopeng Li<sup>*</sup></span>,
          <span>Kuicai Dong<sup></sup></span>,
          <span>Quanhu Zhang<sup></sup></span>,
          <span>Rongju Ruan<sup></sup></span>,
          <span>Xinyi Dai<sup></sup></span>,
          <span>Yasheng Wang<sup></sup></span>,
          <span>Ruiming Tang<sup></sup></span>

        </div>

        <!-- å•ä½è¡Œ -->
        <div class="affil-line text-muted mt-1">
          <span><sup></sup> Huawei Noah's Ark Lab</span>
        </div>
      </div>

      <div class="d-flex flex-row justify-content-center gap-3">
        <a href="https://github.com/Humanity-s-Last-Code-Exam/HLCE">
          <img src="https://img.shields.io/badge/GitHub-Repo-181717.svg?style=for-the-badge&logo=github&logoColor=white"
               alt="github" class="img-fluid" />
        </a>
        <a href="">
          <img src="https://img.shields.io/badge/Paper-ArXiv'25-a55fed.svg?style=for-the-badge" alt="paper" class="img-fluid" />
        </a>
        <a href="https://huggingface.co/spaces/YourUsername/YourProject">
          <img src="https://img.shields.io/badge/Hugging&nbsp;Face-ğŸ¤—-FFD21E.svg?style=for-the-badge"
               alt="huggingface" class="img-fluid" />
        </a>
      </div>

      <div id="notes">
        <h3> News </h3>
        <div class="inline-block mt-3">
          <p>ğŸ“¢ 25â€‘Junâ€‘1: We are excited to release HLCE. Checkout <a href="https://github.com/Humanity-s-Last-Code-Exam/HLCE">ğŸŒ GitHub</a> and <a href="">ğŸ¤— HuggingFace</a>!</p>
        </div>

        <h3> Introduction </h3>
        <div id="notes">
          HLCE is a challenging benchmark of 235 competitive programming problems sourced from the IOI and ICPC World Finals. It features both standard and interactive problems, along with a novel selfâ€‘assessment task designed to evaluate deeper reasoning capabilities.
          By incorporating data from human competitions, HLCE provides metrics that directly compare large language models with elite human programmersâ€”revealing a clear gap in performance. The benchmark is designed to push the boundaries of code generation, encouraging progress toward models that can truly compete at the highest levels of programming expertise.
          <div style="text-align: center;">
            <img src="figs/hlce_cover.png" alt="Cover" style="width: 90%; max-width: 100%; height: auto;" />
          </div>
        </div>
      </div>

      <!-- ======== Benchmark Switch ======== -->
      <div id="notes">
      <h3> LeaderBoard</h3>
      <div class="btn-group my-3" role="group" id="benchmark-toggle">
        <input type="radio" class="btn-check" name="benchmark" id="ICPC" autocomplete="off" checked />
        <label class="btn btn-outline-primary" for="ICPC">ICPC</label>

        <input type="radio" class="btn-check" name="benchmark" id="IOI" autocomplete="off" />
        <label class="btn btn-outline-primary" for="IOI">IOI</label>

        <input type="radio" class="btn-check" name="benchmark" id="Average" autocomplete="off" />
        <label class="btn btn-outline-primary" for="Average">Average</label>
      </div>
        </div>

      <!-- ======== Results Table ======== -->
      <div class="table-responsive w-100">
        <table id="results-table" class="table table-striped table-bordered align-middle"></table>
      </div>

            <!-- ======== Benchmark Switch ======== -->
      <div id="notes">
      <h3> Submitting Custom Models</h3>
        To submit models you can create a pull request on our <a href="https://github.com/Humanity-s-Last-Code-Exam/results"> Results</a> . Particularly, you can copy your model generations folder from `output` to the `submissions` folder and create a pull request. We will review the submission and add the model to the leaderboard accordingly.

      </div>

      <div id="notes" class="w-100 mt-5">
        <h3 class="text-center">Citation</h3>
        <p>If you use <strong>HLCE</strong> in your research, please cite our paper:</p>
        <pre class="mx-auto p-3 bg-light rounded" style="max-width: 700px;"><code class="language-bibtex">@article{hlce2025,
  title   = {Humanity's Last Code Exam: Can Advanced LLMs Conquer Human's Hardest Code Competition?},
  author  = {First Last and Second Author and Third Author},
  journal = {arXiv preprint arXiv:2506.01234},
  year    = {2025}
}</code></pre>
      </div>
    </div>

    </div>

    <!-- ====================================================== -->
    <!-- ======== Script ====================================== -->
    <!-- ====================================================== -->
    <script>
      ////////////////////////////////////////////////////////////////////////
      //  GLOBAL STATE                                                      //
      ////////////////////////////////////////////////////////////////////////
      let tableData = [];
      let tableKeys = [];
      const sortState = new Map();

      ////////////////////////////////////////////////////////////////////////
      //  TABLE HELPERS                                                     //
      ////////////////////////////////////////////////////////////////////////
      const buildHeader = (keys) => {
        const thead = document.createElement('thead');
        const tr = document.createElement('tr');
        const rankTh = document.createElement('th');
        rankTh.textContent = '#';
        tr.appendChild(rankTh);
        keys.forEach((k) => {
          const th = document.createElement('th');
          th.dataset.key = k;
          th.addEventListener('click', handleSortClick);
          updateSortIndicator(th, k);
          tr.appendChild(th);
        });
        thead.appendChild(tr);
        return thead;
      };

      const updateSortIndicator = (th, key) => {
        const dir = sortState.get(key);
        const arrow = dir === 'asc' ? ' â–²' : dir === 'desc' ? ' â–¼' : '';
        th.textContent = key + arrow;
      };

      const buildBody = (rows, keys) => {
        const tbody = document.createElement('tbody');
        rows.forEach((row, idx) => {
          const tr = document.createElement('tr');
          const rankTd = document.createElement('td');
          rankTd.textContent = idx + 1;
          tr.appendChild(rankTd);
          keys.forEach((k) => {
            const td = document.createElement('td');
            if (k === 'Model' && row.URL) {
              td.innerHTML = `<a href="${row.URL}" target="_blank" rel="noopener noreferrer">${row[k]}</a>`;
            } else {
              const v = row[k];
              td.textContent = typeof v === 'number' && !Number.isNaN(v) ? v.toFixed(3) : v;
            }
            tr.appendChild(td);
          });
          tbody.appendChild(tr);
        });
        return tbody;
      };

      const renderTable = () => {
        const table = document.getElementById('results-table');
        table.innerHTML = '';
        table.appendChild(buildHeader(tableKeys));
        table.appendChild(buildBody(tableData, tableKeys));
      };

      ////////////////////////////////////////////////////////////////////////
      //  SORTING                                                          //
      ////////////////////////////////////////////////////////////////////////
      const handleSortClick = (e) => {
        const key = e.currentTarget.dataset.key;
        const current = sortState.get(key);
        const dir = current === 'asc' ? 'desc' : current === 'desc' ? undefined : 'asc';
        if (dir) sortState.set(key, dir); else sortState.delete(key);
        tableData.sort((a, b) => compareValues(a[key], b[key], dir));
        [...sortState.keys()].forEach((k) => { if (k !== key) sortState.delete(k); });
        renderTable();
      };

      const compareValues = (a, b, dir = 'asc') => {
        const m = dir === 'desc' ? -1 : 1;
        const aNum = !Number.isNaN(parseFloat(a));
        const bNum = !Number.isNaN(parseFloat(b));
        if (aNum && bNum) return (parseFloat(a) - parseFloat(b)) * m;
        return String(a).localeCompare(String(b)) * m;
      };

      ////////////////////////////////////////////////////////////////////////
      //  DATA LOADING                                                     //
      ////////////////////////////////////////////////////////////////////////
      const safeNum = (x) => {
        const n = parseFloat(x);
        return Number.isFinite(n) ? n : 0;
      };

      const loadAndRender = async (filename) => {
        try {
          const resp = await fetch(filename);
          if (!resp.ok) throw new Error(`${filename} load failed`);
          const json = await resp.json();
          tableKeys = Object.keys(json[0]).filter((k) => k !== 'URL');
          json.sort((a, b) => safeNum(b['pass@1']) - safeNum(a['pass@1']));
          tableData = json;
          sortState.clear();
          renderTable();
        } catch (err) {
          alert(err.message);
        }
      };

      const loadAverageAndRender = async () => {
        try {
          const [icpcResp, ioiResp] = await Promise.all([
            fetch('ICPC_results.json'),
            fetch('IOI_results.json')
          ]);
          if (!icpcResp.ok || !ioiResp.ok) throw new Error('Failed to load results');
          const [icpcData, ioiData] = await Promise.all([
            icpcResp.json(),
            ioiResp.json(),
          ]);

          const aggMap = new Map();
          // const pass1Candidates = ['Pass@1', 'pass1', 'pass@1 (%)'];
          // const pass5Candidates = ['pass@5', 'pass5', 'pass@5 (%)'];

          pass1Candidates = ['Pass@1', 'pass@1', 'pass1', 'Pass@1 (%)', 'pass@1 (%)'];
          pass5Candidates = ['Pass@5', 'pass@5', 'pass5', 'Pass@5 (%)', 'pass@5 (%)'];

          const accumulate = (rows) => {
            rows.forEach((row) => {
              const name = row.Model;
              if (!aggMap.has(name)) {
                aggMap.set(name, { Model: name, URL: row.URL || '', p1: 0, p5: 0, cnt: 0 });
              }
              const entry = aggMap.get(name);
              const p1 = pass1Candidates.map((k) => row[k]).find((v) => v !== undefined);
              const p5 = pass5Candidates.map((k) => row[k]).find((v) => v !== undefined);
              entry.p1 += safeNum(p1);
              entry.p5 += safeNum(p5);
              entry.cnt += 1;
            });
          };

          accumulate(icpcData);
          accumulate(ioiData);

          const avgRows = Array.from(aggMap.values()).map((e) => ({
            Model: e.Model,
            'Pass@1': e.cnt ? e.p1 / e.cnt : 0,
            'Pass@5': e.cnt ? e.p5 / e.cnt : 0,
            URL: e.URL,
          }));

          avgRows.sort((a, b) => safeNum(b['Pass@1']) - safeNum(a['Pass@1']));
          tableKeys = ['Model', 'Pass@1', 'Pass@5'];
          tableData = avgRows;
          sortState.clear();
          renderTable();
        } catch (err) {
          alert(err.message);
        }
      };

      ////////////////////////////////////////////////////////////////////////
      //  EVENT LISTENERS                                                  //
      ////////////////////////////////////////////////////////////////////////
      document.getElementById('ICPC').addEventListener('change', (e) => {
        if (e.target.checked) loadAndRender('ICPC_results.json');
      });
      document.getElementById('IOI').addEventListener('change', (e) => {
        if (e.target.checked) loadAndRender('IOI_results.json');
      });
      document.getElementById('Average').addEventListener('change', (e) => {
        if (e.target.checked) loadAverageAndRender();
      });

      // initial load
      loadAndRender('ICPC_results.json');
    </script>
  </body>
</html>
